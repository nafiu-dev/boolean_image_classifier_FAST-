{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Build a boolean image classifier FAST using any dataset, with a brief explanation of Convolutional Neural Network (CNN) with code\n",
        "\n",
        "Dataset available at: https://www.kaggle.com/datasets/cashutosh/gender-classification-dataset\n"
      ],
      "metadata": {
        "id": "dvhOdaTCp0DV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ps9hwBwlJ9yE"
      },
      "outputs": [],
      "source": [
        "!unzip -q \"archive.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing required libraries"
      ],
      "metadata": {
        "id": "e1QoNC_mqR4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
      ],
      "metadata": {
        "id": "YNg5IWrsKKmO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading data and processing images"
      ],
      "metadata": {
        "id": "4xDhFpVgqloQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "9hqCTOBmKYmQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrainTest_Datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      validation_split=0.2 # we will use this as test data\n",
        ")\n",
        "Validation_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        ") "
      ],
      "metadata": {
        "id": "Zcx1JkqSKcc6"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = TrainTest_Datagen.flow_from_directory(\n",
        "    './Training',\n",
        "    target_size=(256,256),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training'\n",
        ")\n",
        "Test_data = TrainTest_Datagen.flow_from_directory(\n",
        "    './Training', \n",
        "    target_size=(256,256),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation'# set as test data\n",
        ") \n",
        "Val_data = Validation_datagen.flow_from_directory(\n",
        "    './Validation',\n",
        "    target_size=(256,256),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOdKALLEKcZr",
        "outputId": "54afca2f-b13a-432a-d1cf-7dbde2fa9a77"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 37608 images belonging to 2 classes.\n",
            "Found 9401 images belonging to 2 classes.\n",
            "Found 11649 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igpRh2ZgKcSw",
        "outputId": "184acec3-cc6c-489c-89b1-eed932a67c82"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'female': 0, 'male': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modeling and Training"
      ],
      "metadata": {
        "id": "sAABTBBuq5YA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Conv2D(16, (3,3), 1, activation='relu', input_shape = (256,256,3)),\n",
        "    MaxPooling2D(),\n",
        "\n",
        "    Conv2D(32, (3,3), 1,  activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "\n",
        "    Conv2D(64, (3,3), 1,activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "lkPr2MICKcNi"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\",loss='binary_crossentropy',metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "JBGw2brpLwfl"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mfoqwj5LwYh",
        "outputId": "9aebcc47-4706-4299-8917-ff1f63f1408b"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 254, 254, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 127, 127, 16)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 125, 125, 32)      4640      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 62, 62, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 60, 60, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 30, 30, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 57600)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               14745856  \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,769,697\n",
            "Trainable params: 14,769,697\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
        "history = model.fit(\n",
        "      train_data,\n",
        "      steps_per_epoch=1175,\n",
        "      epochs=20,\n",
        "      validation_data = Val_data,\n",
        "      validation_steps=364,\n",
        "      callbacks=[es]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqFU1GC3LwWB",
        "outputId": "82793452-a9cd-451f-bd32-cafa7a133ac6"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1175/1175 [==============================] - 88s 74ms/step - loss: 0.2678 - accuracy: 0.8943 - val_loss: 0.1988 - val_accuracy: 0.9243\n",
            "Epoch 2/20\n",
            "1175/1175 [==============================] - 86s 73ms/step - loss: 0.1711 - accuracy: 0.9338 - val_loss: 0.1489 - val_accuracy: 0.9391\n",
            "Epoch 3/20\n",
            "1175/1175 [==============================] - 88s 75ms/step - loss: 0.1346 - accuracy: 0.9505 - val_loss: 0.1263 - val_accuracy: 0.9534\n",
            "Epoch 4/20\n",
            "1175/1175 [==============================] - 85s 73ms/step - loss: 0.1013 - accuracy: 0.9630 - val_loss: 0.1293 - val_accuracy: 0.9517\n",
            "Epoch 5/20\n",
            "1175/1175 [==============================] - 85s 73ms/step - loss: 0.0733 - accuracy: 0.9730 - val_loss: 0.1471 - val_accuracy: 0.9506\n",
            "Epoch 6/20\n",
            "1175/1175 [==============================] - 87s 74ms/step - loss: 0.0510 - accuracy: 0.9810 - val_loss: 0.1827 - val_accuracy: 0.9447\n",
            "Epoch 7/20\n",
            "1175/1175 [==============================] - 87s 74ms/step - loss: 0.0324 - accuracy: 0.9881 - val_loss: 0.1802 - val_accuracy: 0.9505\n",
            "Epoch 8/20\n",
            "1175/1175 [==============================] - 85s 72ms/step - loss: 0.0243 - accuracy: 0.9915 - val_loss: 0.2265 - val_accuracy: 0.9492\n",
            "Epoch 8: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "4aFhrJiVrGdZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(Test_data, verbose=0)\n",
        "print('\\nTest accuracy:', np.round(test_acc * 100,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "119_6qRALwPl",
        "outputId": "001d35d6-025f-4bbb-e259-86003a7abfd6"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test accuracy: 94.767\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Real time prediction"
      ],
      "metadata": {
        "id": "jXMo3b_KrTMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RealPredict(img_path):\n",
        "  img_test = tf.io.read_file(img_path)\n",
        "  img_test = tf.io.decode_jpeg(img_test , channels = 3)\n",
        "  img_test = tf.image.resize(img_test , [256 , 256] , method=\"nearest\")\n",
        "  yhat = model.predict(np.expand_dims(img_test, 0))\n",
        "  if yhat < 0.5: \n",
        "    print(f'Predicted the person a female')\n",
        "  else:\n",
        "      print(f'Predicted the person a male')"
      ],
      "metadata": {
        "id": "RmryBQzRM_iA"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# {'female': 0, 'male': 1}"
      ],
      "metadata": {
        "id": "w3P5W1l2MbH6"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RealPredict('Training/female/131422.jpg.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGwDqop-MbFf",
        "outputId": "51270d9e-acce-4ec5-f00c-548890b7d6a3"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 15ms/step\n",
            "Predicted the person a female\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RealPredict('Training/male/090639.jpg.jpg')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9-7mk-9MbDF",
        "outputId": "1d8d908c-2b28-4d5d-d582-2ef13ba1c68c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "Predicted the person a male\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "efbJcUyWMa6Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}